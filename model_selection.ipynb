{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit.Chem import PandasTools, AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from statistics import mean\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genMorgan(mol):\n",
    "    funcFPInfo=dict(radius=3,nBits=2048,useFeatures=False,useChirality = False)\n",
    "    #print(type(mol))\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(mol,**funcFPInfo)\n",
    "\n",
    "def convertVector(v):\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(v,arr)\n",
    "    return arr\n",
    "\n",
    "def balanceNearMiss(df,near_miss_strat):\n",
    "    bigger_set = df.loc[df.Outcome == 1]\n",
    "    smaller_set = df.loc[df.Outcome == 0]\n",
    "    if len(bigger_set) < len(smaller_set):\n",
    "        bigger_set = df.loc[df.Outcome == 0]\n",
    "        smaller_set = df.loc[df.Outcome == 1]\n",
    "    if len(smaller_set)/len(bigger_set) < .9:\n",
    "        X = pd.DataFrame(df['maccs'].apply(convertVector).tolist())\n",
    "        sampler = NearMiss(sampling_strategy='majority',version=near_miss_strat)\n",
    "        fitted = sampler.fit_resample(X,df.Outcome)\n",
    "        sample_idx = sampler.sample_indices_\n",
    "        return df.iloc[sample_idx,:].copy()\n",
    "    else:\n",
    "        return df\n",
    "                            \n",
    "def stats(y_train, y_pred):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, y_pred)\n",
    "    print(confusion_matrix)\n",
    "    accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "    roc_auc_score = metrics.roc_auc_score(y_train, y_pred)\n",
    "    Kappa = metrics.cohen_kappa_score(y_train, y_pred, weights='linear')\n",
    "    # True and false values\n",
    "    TN, FP, FN, TP = confusion_matrix.ravel()  \n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    SE = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    SP = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Correct classification rate\n",
    "    CCR = (SE + SP)/2\n",
    "    d = dict({'Accuracy': accuracy,\n",
    "         'AUC': roc_auc_score,\n",
    "         'Kappa': Kappa,\n",
    "         'CCR': CCR,\n",
    "         'Sensitivity': SE,\n",
    "         'PPV': PPV,\n",
    "         'Specificity': SP,\n",
    "         'NPV': NPV})\n",
    "    return pd.DataFrame(d, columns=d.keys(), index=[0]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Binarize Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = PandasTools.LoadSDF(\"/home/francis/Documents/MML/StopTox/Data/1-Acute_dermal_2616_st.sdf\")\n",
    "df['Outcome'] = df['LD50'].map(lambda x: 1 if float(x) > 2000 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MACCS Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maccs'] = df['ROMol'].apply(Chem.rdMolDescriptors.GetMACCSKeysFingerprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Using NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = balanceNearMiss(df,2)\n",
    "# df_balanced = balanceNearMiss(df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_maccs = np.array(list(df_balanced['maccs'])).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RFC(n_estimators=1000,\n",
    "            criterion='entropy',\n",
    "            max_features='sqrt',\n",
    "            max_depth=None,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=1,\n",
    "            bootstrap=True,\n",
    "            random_state=24,\n",
    "            verbose=1,\n",
    "            n_jobs=-1)\n",
    "rf_random = RandomizedSearchCV(estimator = model,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100, cv = 5,\n",
    "                               verbose=2,\n",
    "                               random_state=24,\n",
    "                               n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   44.0s\n",
      "/home/francis/Programs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 10.0min finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=2)]: Done 1600 out of 1600 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       "            n_jobs=2, oob_score=False, random_state=24, verbose=1,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=24, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_random.fit(training_maccs,df_balanced.Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rf_random.best_params_\n",
    "chosen_maccs_model = RFC(n_estimators=params['n_estimators'],\n",
    "            criterion='entropy',\n",
    "            max_features=params['max_features'],\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            min_samples_leaf=params['min_samples_leaf'],\n",
    "            bootstrap=params['bootstrap'],\n",
    "            random_state=24,\n",
    "            verbose=1,\n",
    "            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['maccs_pred'] = [0 for _ in range(len(df_balanced))]\n",
    "pred_pos = df_balanced.columns.get_loc('maccs_pred')\n",
    "outcome_pos = df_balanced.columns.get_loc('Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1600 out of 1600 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 1.74 s, total: 33.4 s\n",
      "Wall time: 16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1600 out of 1600 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skf = StratifiedKFold(5)\n",
    "for train_idx, test_idx in skf.split(training_maccs,df_balanced.Outcome):\n",
    "    #print(training_maccs[train_idx],df.Outcome[train_idx])\n",
    "    chosen_maccs_model.fit(training_maccs[train_idx],df_balanced.iloc[train_idx,outcome_pos])\n",
    "    df_balanced.iloc[test_idx,pred_pos] = chosen_maccs_model.predict(training_maccs[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[472 219]\n",
      " [223 468]]\n"
     ]
    }
   ],
   "source": [
    "maccs_result = stats(df_balanced.Outcome,df_balanced.maccs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>CCR</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>PPV</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>NPV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "   Accuracy   AUC  Kappa   CCR  Sensitivity   PPV  Specificity   NPV\n",
       "0      0.68  0.68   0.36  0.68         0.68  0.68         0.68  0.68"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maccs_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['morgan'] = df_balanced['ROMol'].apply(lambda x: genMorgan(x))\n",
    "training_morgan = np.array(list(df_balanced['morgan'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.8min\n",
      "/home/francis/Programs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_random.fit(training_morgan,df_balanced.Outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = rf_random.best_params_\n",
    "chosen_morgan_model = RFC(n_estimators=params['n_estimators'],\n",
    "            criterion='entropy',\n",
    "            max_features=params['max_features'],\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            min_samples_leaf=params['min_samples_leaf'],\n",
    "            bootstrap=params['bootstrap'],\n",
    "            random_state=24,\n",
    "            verbose=1,\n",
    "            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['morgan_pred'] = [0 for _ in range(len(df_balanced))]\n",
    "pred_pos = df_balanced.columns.get_loc('morgan_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "skf = StratifiedKFold(5)\n",
    "for train_idx, test_idx in skf.split(training_morgan,df_balanced.Outcome):\n",
    "    #print(training_maccs[train_idx],df.Outcome[train_idx])\n",
    "    chosen_morgan_model.fit(training_morgan[train_idx],df_balanced.iloc[train_idx,outcome_pos])\n",
    "    df_balanced.iloc[test_idx,pred_pos] = chosen_maccs_model.predict(training_morgan[test_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
