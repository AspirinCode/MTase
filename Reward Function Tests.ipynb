{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "#Basic stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "# Chemistry\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "# Initialize tqdm progress bar\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA / ReLeaSE\n",
    "import sys\n",
    "sys.path.append('./release/')\n",
    "from release.stackRNN import StackAugmentedRNN\n",
    "from release.data import GeneratorData\n",
    "from release.utils import canonical_smiles, time_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "import torch.nn.functional as F\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available()          = True\n",
      "torch.cuda.device_count()          = 1\n",
      "torch.cuda.current_device()        = 0\n",
      "torch.cuda.device('cuda')          = <torch.cuda.device object at 0x000001E142851128>\n",
      "torch.cuda.get_device_name()       = GeForce GTX 1060\n",
      "torch.cuda.get_device_capability() = (6, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"torch.cuda.is_available()          =\", torch.cuda.is_available())\n",
    "print(\"torch.cuda.device_count()          =\", torch.cuda.device_count())\n",
    "print(\"torch.cuda.current_device()        =\", torch.cuda.current_device())\n",
    "print(\"torch.cuda.device('cuda')          =\", torch.cuda.device('cuda'))\n",
    "print(\"torch.cuda.get_device_name()       =\", torch.cuda.get_device_name(0))\n",
    "print(\"torch.cuda.get_device_capability() =\", torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fake_predictor():\n",
    "    \"\"\" Makes fake predictions, just for testing purposes\"\"\"\n",
    "    \n",
    "    def __init__(self, random_seed=42):\n",
    "        self.random_seed = random_seed\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    def predict(self, data, stdev=1.0):\n",
    "        prediction = stdev * np.random.randn() + data\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fake_generator():\n",
    "    \"\"\" Generate random numbers centered at a mean. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def generate(self, n_to_generate, mean=0.01, stdev=1.0):\n",
    "        new = stdev * np.random.randn(n_to_generate) + mean\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(data, threshold):\n",
    "    if data > threshold:\n",
    "        return 10.0\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = fake_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = fake_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "n_iterations = 100\n",
    "threshold = 0.01\n",
    "delta_thresh = 1.0\n",
    "rewards = []\n",
    "population = 1000\n",
    "predictions = np.empty(population)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    new_data = generator.generate(population, threshold)\n",
    "    for i, data in enumerate(new_data):\n",
    "        predictions[i] = predictor.predict(data)\n",
    "        # Normally, would need to calculate the reward function here.\n",
    "        \n",
    "    above_threshold = (predictions > threshold).sum() / population\n",
    "    \n",
    "    plt.hist(predictions)\n",
    "    \n",
    "    if above_threshold > 0.51:\n",
    "        rewards.append(True)\n",
    "        threshold = threshold + delta_thresh\n",
    "print(\"Final threshold =\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist([])\n",
    "hist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fromfunction((lambda x: x**2) ,(10,0), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fromfunction(lambda i, j: i == j, (3, 3), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNC-ML (Python 3.7.1)",
   "language": "python",
   "name": "unc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
